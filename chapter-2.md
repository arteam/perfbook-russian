# Глава 2
## Введение

Параллельное программирование заслужило репутацию как одна из самых сложных областей, с которыми программист может столкнуться. Научные работы и книги предупреждают об опасностях деддлока, лайвлока, гонки условий, неопределенности, ограничений закона Амдала по масштабируемости и чрезмерных задержках в реальном времени. И эти опасности вполне реальны; мы, авторы, собрали неисчислимые года опыта работы с ними: все эмоциональные шрамы, седые волосы и их потерю, которая появляется после встречи с такими опытами.

Однако, новые технологии, которые сложны для использовании в при появлении, неизбежно становятся проще со временем. Например, в свое время редкое умение водить машину сейчас является обычной вещью во многих странах. Такое большое изменение произошло по двум базовым причинам: (1) машины стали дешевле и более легко доступны, таким образом большее количество людей получило возможность научится водить и (2) машины стали более просты в эксплуатации благодаря автоматическим трансмиссиям, автоматическим дросселям, автоматическим стартерам, значительно увеличинной надежности и набору других технологических улучшений.

Это же является правдой и для других технологий, включая компьютеры. Теперь не нужно работать с перфокартами для того, чтобы программировать.
Умные таблицы позволяют большинству непрограммистов получать такие результаты от их компьютеров, получение которых требовало бы команду специалистов несколько десятков лет назад. Возможно, наиболее яркий пример это веб-серфинг и создание контента. С начала 2000-x с помощью разных распространенных социально-сетевых инструментов это могут делать люди без специального обучения и тренировки. Не так давно как в 1968 году, такое создание контента было далеким исследовательским проектом [Eng68], описываемым в свое время как "приземление летающей тарелки на лужайку перед Белым домом".

Следовательно, если вы желаете спорить, что параллельное программирование останется таким же сложным как оно воспринимается многими сейчас, это вы, кто должен приводить доказательства, при этом не забывая о многих веках контр-примеров в различных областях человеческих достижений. 

### Исторические сложности параллельного программирования

Как следует из ее названия, это книга преследует другой подход. Вместо того, чтобы жаловаться на сложности параллельного программирования, она вместе этого изучает причины, почему же параллельного программирование сложно и помогает читателю преодолеть эти сложности. Как мы дальше увидим, эти сложности разделяются на несколько категорий, включая:

1. Исторически высокую цену и относительную редкость параллельных систем;
2. Отсутствие опыта работы с параллельными системами у типичных исследователей и практиков;
3. Малое количество публично доступного параллельного кода;
4. Отсуствие широко понимаемой инженерной дисциплины параллельного программирования;
5. Высокие накладные расходы на коммуникацию по сравнению с обработкой данных, даже в сильно связанных вычислительных системах с разделяемой памятью.

Многие из этих исторических сложностей уже на пути к преодолению. 
1. За последние несколько десятков лет благодаря закону Мура цена параллельных систем упала с порядка цены на дом до порядка цены на велосипед. Научные работы, говорящие о преимуществах мультиядерных процессоров были опубликованы в начале 1996 года [OHN+96]. IBM одновременно внедрила многопоточность в передовую линейку процессоров POWER в 2000 и мультиядерность в 2001. Intel внедрила гиперпоточность в их двухядерные процессоры в 2005. Sun последовала за ними с мультиядерным/мультипоточным процессором Niagara в конце 2005. На самом деле, в 2008 году уже было сложно найти однопроцесоррную настольную систему, а одноядерные процессоры остались только в нетбуках и встроенных устройствах. К 2012 году даже смартфоны начали выпускаться с несколькими процессорами.

2. Приход дешевых и широкодоступных мультиядерных систем, значит, что в свое время редкий опыт параллельного программирования теперь доступен практически каждому исследователю и практику. На самом деле, параллельные системы сейчас по карману даже школьнику и любителю. Мы, следовательно, можем ожидать большое увеличение уровня открытий и инноваций в областях, окружающих параллельные системы. Эта увеличивающаяся знакомость через некоторе время сделает однажды ужасно дорогую область параллельного программирования более дружелюбной и обычной. 

3. В 20 веке, большинство большие системы с используем высоко распаралезированного программного обеспечения были закрытыми и тщательно охраняемыми проприетарными секретами. На контрасте с этим, 21 век увидел многочисленные проекты параллельного программного обеспечния с открытым кодом (следовательно  публично доступых), включая ядро Linux [Tor03c], системы управления базами данных [Pos08, MS08] и систем передач сообщений [The08, UoC08]. Эта книга в основном будет сфокусирована на ядре Linux, по предоставит много материала, подходящего и для прикладных приложений.

4. Даже несмотря н то, что большинство проектов параллельного программирования в 1980-х и в 1990-х были проприетарными, эти проекты дали жизнь сообществу разработчиков, кто понимает инженерную дисциплину, необходимую для разработки параллельного кода производственного качества. Одна из главных целей этой книги показать эту инжереную дисциплину.

5. К сожалению, с пятой проблемой, высокой ценой коммуникации по отнощению к обработке данных, все еще борятся. Хотя к этой проблеме было приковано много внимания с начала нового тысячилетия, согласно Стивену Хокингу, конечная скорость света и атомная природа материи, скорее всего ограничит прогресс в этой области [Gar 07, Moo03]. К счастью, с этой проблемой борятся с конца 1980-х годов, так что вышеупомянутая инженерная дисциплина разработала практичные и эффективные стратегии для ее обхождения. В добавок, проектировщики аппаратных обеспечения все более знакомы с этими проблемами, так что возможно будущее аппаратное обеспечение будет более дружелюбно к параллельному программному обеспечению, как было обсуждается в разделе 3.3.

**Быстрый вопрос 2.1:** Ну хватит!! Параллельное программирование было невооброзимо сложным многие десятилетия. Вы же, судя по всему, указывате на то, что оно не так сложно. На что вы намекаете?
Несмотря на то, что параллельное программирование может и не так сложно, как оно преподносится, оно все еще сложнее, чем последовательное программирование.

**Быстрый вопрос 2.2:** Как параллельное программирование вообще может быть таким же легким, как последовательное программирование?
Следовательно, имеет смысл рассмотреть альтернативы параллельноому программированию. Однако, невозможно аргументировано рассматривать альтернативы параллельному программированию без понимания его целей. Эта тема рассматривается в следующем разделе.

## Цели параллельного программирования

Три главные цели параллельного программирования(в дополнение к целям последовательного программирования):
1. Производительность;
2. Эффективность;
3. Общность

**Быстрый вопрос 2.3:** Серьезно??? А что насчет корректности, поддерживаемости, надежности и так далее?

**Быстрый вопрос 2.4:** И если корректность, поддерживаемость и надежность не попали в список, почему попали эффективность и общность?

**Быстрый вопрос 2.5:** Учитывая, что  намного сложнее доказать корректность параллельных программ, чем последовательных, опять, не должна ли все-таки корректность быть в списке?

**Быстрый вопрос 2.6:** Как насчет того, чтобы просто весело проводить время?
Каждая из этих целей тщательно разобрана в следующих разделах:

### 2.2.1 Производительность
Производительность - это главная цель большинства усилий, связанных с параллельным программированием. В конце концов, если производительность не забота, почему бы не сделать себе услугу: просто писать последовательный код и быть счастливым? Это будет намного проще и скорее всего вы сделате намного больше вещей быстрее.

**Быстрый вопрос 2.7:** Разве не существует ситуаций, когда парралельное программирование, это не о производительности?
Имейте ввиду, что "производительность" толкуется здесь довольно широко, включая как масшатабируемость(производильность каждого процессору), так и эффективность(например, производительность на ватт энергии).

Тем не менее, фокус производительности сдвинулся с аппаратного обеспечения к параллельному программному обеспечению. Этот сдвиг происходит из-за того, что несмотря на то, что закон Мура продолжает доставлять увелечение плотности транзисторов, он перестал доставлять увелечение производителоности для традиционных однопоточных программ. Это можно увидеть на графике 2.1, который показывает, что написание однопоточного кода и простое ожидание того, что через год или два процессор догонится до нужной производительности может быть уже не вариантом. Учитывая последние тенденции всех главных производителей по отношению к мультиядерным/мультипоточным системам, параллеизм это выход для тех, кто хочет достичь максимальной производительность от их систем.

![График 2.1](../master/clockfreq.png?raw=true)

График 2.1: Тенденция показателя MIPS/тактовая частота для процессоров Intel

Даже так, производительность является более важной, чем масштабируемость, особенно учитывая, что наиболее простой способ достичь линейной масштабируемости - это понизить производительность каждого процессора [Tor01]. Если вам дана 4-процессорная система, что вы предпочтете: программу, которая выполняет 100 транзакций в секунду на одном процессору, но не масштабируется или программу, которая выполняет 10 транзкаций в секунду, но отлично масштабируется. Первый вариант смотрится лучше, однако ответ может изменится, если у вас появится 32-процессорная система. 

Однако, только потому что у вас есть несколько процессоров, вы не обязаны все их использовать, особенно учитывая недавние подешевение цен на мультипроцессорные системы. Ключевая идея в том, что параллельное программирование, в основном это оптимизация производительности и, следовательно, все лишь возможная оптимизация из многих доступных. Если ваша программа достаточна быстра в таком виде, в котором она сейчас написана, нет причины оптимизировать ее, как путем распараллеливания, так и путем применения потенциальных оптимизация для последовательных программ. Кстати, если вы собираетесь применить паралеллизм как оптимизацию к последовательной программе, вам надо будет сравнивать параллельные алогритмы с лучшими последовательными. Это может потребовать некоторого внимания, так как слишком много работ игнорируют последовательные аналоги при анализе производительности параллельных алгоритмов.

### 2.2.2 Эффективность
**Быстрый вопрос 2.8** Зачем нужна вся эта болтовня о нетехнических вопросах??? И не только о нетехнических вопросах, а и эффективности всех этих вещей? Кого это волнует?

Эффективность становилась все более важной в последние десятилетия. Для того чтобы увидеть эту тенденцию, имейте ввиду, что цена ранних компьютеров равнялась десяткам миллионов долларов, в то время, как цена как средняя зарплата инженера были порядка нескольких десятков тысяч долларов в год. Если выделенная команда из десяти инженеров увеличивала производительность ткой машины даже на 10%, то их зарплаты окупались во много раз.

Одной из таких машин был CSIRAC, старейший все еще целый компьютер с хранимой программой в памяти. Он был введен в работу в 1949 году[Mus04, Mel06]. Так как эта машина была построена в дотранизестерную эру, то она состояла из 2000 электронных ламп, работала с тактовой частотой 1 КГц, потребляла 30 кВт энергии и весила более, чем три тонны. Учитывая, что эта машина имела всего 768 слов оперативной памяти, можно без опасения сказать, что она не страдала от проблем с производительностью, с которыми сталкиваются современные масштабные программные проекты.

Сегодня достаточно трудно купить машину с такой маленькой вычислительной мощностью. Возможно, ближайший эквивалент - это 8-битный встраевамый микропроцессор на базе древнего Z80 [Wik08], но даже старый Z80 имел тактовую частоту процессора, более чем в 1000 раз превышающую CSIRAC. Процессор Z80 имел 8500 тысяч транзисторов и мог быть куплен в 2008 году менее, чем за 2$ US за штуку партиями по тысяче штук. На контрасте с CSIRAC цена разработки программного обеспечения является всем, чем угодно, но не важным фактором для Z80.

CSIRAC и Z80 - две точки в долговременной тенденции, как мы можем видеть на графике 2.2.

![График 2.2](../master/mipsperbuck.png?raw=true)
График 2.2: MIPS на кристалл для процессоров Intel

Этот график отображает апроксимацию вычислительной мощности на кристалл за последние три десятилетия и показывает постоянное увеличение этой величины на 4 порядка. Надо учитывать, что приход мультиядерных процессоров сделал возможным продолжение этого  увеличения, несмотря на потолок тактовой частоты, с которым столкнулись инженеры в 2003 году.

Одно из неизбежных последствий быстрого уменьшения цены на аппаратное обеспечение, это то, что эффективность программного обеспечения начала становится все более важной. Теперь недостаточно просто эффективно использовать аппаратное обеспечение: теперь вместе с ним необходимо крайне эффективно использовать разработчиков программного обеспечения. Это давно уже не новость для последовательного аппаратного обеспечения, но параллельное аппаратное обеспечение стало недорогим только недавно. Именно поэтому высокая эффективность стала критично важной при создании параллельного программного обеспечения.

**Быстрый вопрос 2.9:** Учитывая насколько дешевыми стали параллельные системы, как люди могут позволить платить программистам, работащими с этими системами?

Возможно, в свое время единственной целью параллельного программного обеспечения была производительность. Теперь же, однако, эффективность выходит из тени.

### 2.2.3 Общность

Один из способов оправдать высокую цену разработки параллельного программного обеспечения, это достижение максимальной общности.
При всех прочих равных, более общный программный артефакт может быть распространен между большим количеством пользователей, чем менее общный. 

К сожалению, за счет общности часто приходится жертвовать производительностью, эффективностью или тем и другим. Для того чтобы увидеть это, рассмотрим следующие популярные программмные среды:

**С/C++ "блокировки плюс потоки"** : Эта категория, которая включает потоки POSIX (pthreads) [Ope97], потоки Windows и другие среды уровня ядра операционной системы, предлагает отличную производительностью (по крайней мере в границах одной симметричной мультипроцессорные системы (SMP-системы)) и хорошую общность. Жаль, что только эффективность относительно низка. 

**Java** : Это язык общего назначение и по своей природе мультипоточная программная среда. Он, по широко распространненому мнению, предлагает большую эффективность, чем C или C++ за счет автоматической сброки мусора и большой стандартной библиотеки. Однако его производительность, несмотря на то что она была сильна улучшена в начале 2000-х годов, уступает С и С++.

**MPI** : Этот интерфейс передачи сообщений [MPI08], на котором  работают крупнейшие научные и технические вычислительные кластерами в мире. Он предалагает не имеющие равных производительность и масштабируемость. В теории, MPI является интерфейсом общего назначения, но в большинстве своем используется для научных и технических вычислений. Его эффективность, по мнению многих, даже ниже, чем у подхода С/C++ "блокировки плюс потоки". 

**OpenMP** : Это набор директив для компилятора, который может быть использован для распаралленивания циклов. Следовательно, он крайне специфичен для этой задачи и эта специфичность часто ограничивает производительность. Однако, OpenMP намного легче в использовании, чем MPI или С/C++ "блокировки плюс потоки".

**SQL** : Язык структурных запросов [Int92] специфичен для реляционных баз данных. Однако, его производительность вполне хороша, что показано тестами совета по производительности обработки транзакций (TPC benchmark) [Tra01]. Эффективность отлична. Факт, что SQL позволяет людям эффективно использовать большие параллельные системы, несмотря на их малые или вообще отсутствие знаний о принципах парралельного программирования. 



