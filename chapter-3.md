# Глава 3

## Аппаратное обеспечение и его повадки

Большинство людей имеют интуитивное понимание того, что передача сообщений между системами более дороже, чем выполнение простых вычислений в рамках одной системы. Однако, не всегда ясно, что коммуникация между потоками в рамках одной системы с разделенной памятью может быть тоже вполне дорогой. Эта глава рассматривает цену синхронизации и коммуникации в рамках такой системы. Эти несколько страниц все лишь покажут вершину айсберга дизайна параллельного аппаратного обеспечения с разделенной памятью. Читатели, желающие получить больше деталей, могут начать с последного издания классической книги Хеннесси и Паттерсона [HP95].

**Быстрый вопрос 3.1:**  Зачем программистам параллельных систем учить низкоуровненевые свойства аппартаного обеспечения? Не будет ли проще, лучше, и более обще отстаться на более высоком уровне абстракции?

## 3.1 Обзор

Беззаботные читатели спецификаций компьютерных систем могут прийти к выводу, что производительность процессоров и забег на чистой дороге, как показано на графике 3.1, где победу всегда одерживает быстрейший.

![График 3.1](../master/cartoons/trackmeet.png?raw=true)

График 3.1 Производительность процессоров в забеге

Хотя есть несколько процессорных бенчмарков, которые берут за основу идеал, показанный на графике, реальные программы больше похожы на бег с препятствиями, чем на забег по дорожкам. Это происходит из-за внутренней архитектуры процессоров, которая сильно изменилась за последние несколько десятков лет благодаря закону Мура. Эти изменения показаны в следующих разделах.

### 3.1.1 Конвейерные процессоры

Как работал в начале 1980-х типичный микропроцессор: он выбирал инструкцию, декодировал ее и затем выполнял. В итоге требовалось *как минимум* 3 такта, чтобы обработать одну инструкцию перед переходом к следующей. На контрасте, типичный процессор конца 1990-х - начала 2000-х выполнят много инструкций одновременно, используя глубокий "конвейер" для управления потоком инструкций внутри процессора. Эти современные аппаратные возможности могут сильно улучшить производительность, как показано на графике 3.2.

![График 3.2](../master/cartoons/old_man_and_brat.png?raw=true)

**Новый** : *4.0 Гц тактовая частота, 20 Мб кэша 3 уровня, 20 уровненый конвейер*

**Старый**: *Единственный конвейер который мне нужен, это тот, который остудит этого горячего молокососа*

График 3.2 Старый и новый процессор

Достижение полной производительности с процессором, который имеет длинный конвейер, требует высокопредсказуемого потока управления во время программы. Подходящий поток может быть предоставлен, если программа в основном работает в узких циклах. Например, выполняет арифметику на больших матрицах или векторах. В этом слуае процессор корректно предскажет, что ветка в конце цикла будет достигнута почти во всех случаях. В итоге конвейер будет полным и процессор будет работать на полной скорости.

Однако, предположим, что мы имеем либо программу с большим количеством коротких циклов или объектно-ориентированную программу с большим количеством виртуальных объектов, которые могут ссылаться на реальные объекты, которые имеют различные реализации для часто вызываемых методов. В этих случаях сложно или даже невозможно для процессора предсказать какая ветка будет исполнена. Процессор, следовательно, вынужден либо простаивать, ожидая, что поток выполнения продвинется до момента, когда можно точно знать какая ветка будет исполнена, или догадываться. И для программ с непредсказуемым потоком управления - часто догадываться неправильно. Неправильные догадки могут быть очень дорогими, так как процессор вынужден выбросить все результаты инструкций, которые были выполнены спекулятивно. Более того, в независимости от того, простаивает процессор или догадывается, конвейер будет пустым и будет требовать наполнения. Это приведет к простоям, которые могут значительно уменьшить производительность, как ярко показано на графике 3.3. 

![Рисунок 3.3](../master/cartoons/pipeline.png?raw=true)

Рисунок 3.3 Процессор встречает сброс конвейера

К сожалению, сбросы конвейера не единственные опасности на дорожке с препятствиями, которые современный процессор обязан обойти. Следующий раздел описывает опасности получения данных из памяти.

## 3.1.2 Доступ к памяти

В 1980-х годах для микропроцессор часто мог загрузить значение из памяти быстрее, чем выполнить инструкцию. В 2006 году микропроцессор имеет возможность выполнять сотини или даже тысячи интсрукций за время единичного доступа к памяти. Это несоотвествие происходит из-за того, что закон Мура увеличил производительность процессоров с намного большей степенью, чем производительность памяти (стоит учитывать степень, с которой вырос размер памяти). Для примера, типичный компьютер 1970-x мог иметь 4 килобайта (да, килобайта, не мегабайта, не говоря уже о гигабайтах) оперативной памяти с однотактовым доступом. В 2008 проектировщики процессорров все еще могут создать 4 килобайтную память с однотактовым доступом, даже на системах с тактовами частотами в несолько гигагерц. И они часто создают такую память, только она теперь называется "кэш 0 уровня" и она довольно больше, чем 4 килобайта.

Несмотря на то что большие кэши, доступные на современных микропроцессорах, могут сделать довольно многое для борьбы с задержками доступа к памяти, для успешной работы они требуют высоко предсказуемых паттернов доступа. К сожалению, типичные операции, такие как обход связного списка, высоко непредсказуемы. В конце концов, если бы паттерны был предсказуемы, мы, программисты, не беспокоилсь бы об указателях, верно?

![Рисунок 3.4](../master/cartoons/memory_reference.png?raw=true)

Рисунок 3.4 Процессор встречает ссылку в памяти

Как видно из рисунка 3.4, ссылки на память часто являются серьезными препятствиями для современных процессоров.

До сих пор, мы рассматривали только препятствия, которые могут возникнуть во время исполнения процессором однопоточного кода. Мультипоточность представляется дополнительные препятсвия процессору, как описано в следующих разделах.

### 3.1.3 Атомарные операции

Одними их таких препятсвий являются атомарные операции. Сама идея атомарной операции в некотром роде конфликтует структурой "сборочной линии" современной процессорного конвеера. К чести проектировщиков аппаратного обеспечения, современные процессоры используют некоторые количестов крайне умных трюков, чтобы заставить эти операции *выглядеть* атомарными, даже несмотря на то, что они на самом дела выполняются по частям. Но даже так, все равно существуют случаи, когда конвеер обязан быть задержан или даже сброшен, для того чтобы определенная атомарная операциия выполнилась корректно. 

Итоговый эффект на производительность показан на рисунке 3.5.

![Рисунок 3.5](../master/cartoons/atomic_reference.png?raw=true)

Рисунок 3.5 Процессор встречает атомарную операцию

К содалению, атомарные операции обычно применяются только к одинарным частям данных. Так как многие параллельные алгоритмы требуют поддержки ограничений порядка выполнения между обновлениями нескольких элементов данных, то большинство процессоров предоставляют барьеры памяти. Эти барьеры также являются препятсвиями, который подрывают производительность, как описано в следующем разделе.

**Быстрый вопрос 3.2:** Какие типы машин разрешали бы атомарные операции над несколькими элементами данных?

К счастью, проектировщики процессоров сильно сфокусировались на атомарных операциях. Как итог, в начале 2012 года они сильно уменьшили (но, конечно, не исключили) накладные расходы этих операций.

### 3.1.4 Барьеры памяти

Барьеры памяти будут рассмотрены более глубоко в разделе 14.2 и приложении C. Сейчас же рассмотрим следующую простую критическую секции на основе лока.

```
1 spin_lock(&mylock);
2 a = a + 1;
3 spin_unlock(&mylock);
```

Если бы процессор не был ограничен в выполнение этих команд в том порядке, в котором они указаны, то переменная "a" могла бы быть инкрементирована без защиты локом "mylock". Это, без сомнения, разрушило бы весь смысл захвата лока. Для того, чтобы предотвратить столь разрушительные перестановки, блокировочные примитивы явно или неявно содержат барьеры памяти. Так как весь смысл этих барьеров в том, чтобы предовратить перестановки процессором команд с целью увеличения производительности, то барьеры памяти почти всегда ее ухудшают, что показано на рисунке 3.6.
 
Также как и с атомарными операциями, проектировщики аппаратного обеспечения много и упорно работали для того чтобы уменьшить накладные расходы барьеров памяти и добились в этом значимого прогресса.

![Рисунок 3.6](../master/cartoons/memory_barrier.png?raw=true)

Рисунок 3.6 Процессор встречает барьер памяти
