# Глава 3

## Аппаратное обеспечение и его повадки

Большинство людей имеют интуитивное понимание того, что передача сообщений между системами более дороже, чем выполнение простых вычислений в рамках одной системы. Однако, не всегда ясно, что коммуникация между потоками в рамках одной системы с разделенной памятью может быть тоже вполне дорогой. Эта глава рассматривает цену синхронизации и коммуникации в рамках такой системы. Эти несколько страниц все лишь покажут вершину айсберга дизайна параллельного аппаратного обеспечения с разделенной памятью. Читатели, желающие получить больше деталей, могут начать с последного издания классической книги Хеннесси и Паттерсона [HP95].

**Быстрый вопрос 3.1:**  Зачем программистам параллельных систем учить низкоуровненевые свойства аппартаного обеспечения? Не будет ли проще, лучше, и более обще отстаться на более высоком уровне абстракции?

## 3.1 Обзор

Беззаботные читатели спецификаций компьютерных систем могут прийти к выводу, что производительность процессоров и забег на чистой дороге, как показано на графике 3.1, где победу всегда одерживает быстрейший.

![График 3.1](../master/cartoons/trackmeet.png?raw=true)

График 3.1 Производительность процессоров в забеге

Хотя есть несколько процессорных бенчмарков, которые берут за основу идеал, показанный на графике, реальные программы больше похожы на бег с препятствиями, чем на забег по дорожкам. Это происходит из-за внутренней архитектуры процессоров, которая сильно изменилась за последние несколько десятков лет благодаря закону Мура. Эти изменения показаны в следующих разделах.

### 3.1.1 Конвейерные процессоры

Как работал в начале 1980-х типичный микропроцессор: он выбирал инструкцию, декодировал ее и затем выполнял. В итоге требовалось *как минимум* 3 такта, чтобы обработать одну инструкцию перед переходом к следующей. На контрасте, типичный процессор конца 1990-х - начала 2000-х выполнят много инструкций одновременно, используя глубокий "конвейер" для управления потоком инструкций внутри процессора. Эти современные аппаратные возможности могут сильно улучшить производительность, как показано на графике 3.2.

![График 3.2](../master/cartoons/old_man_and_brat.png?raw=true)

**Новый** : *4.0 Гц тактовая частота, 20 Мб кэша 3 уровня, 20 уровненый конвейер*

**Старый**: *Единственный конвейер который мне нужен, это тот, который остудит этого горячего молокососа*

График 3.2 Старый и новый процессор

Достижение полной производительности с процессором, который имеет длинный конвейер, требует высокопредсказуемого потока управления во время программы. Подходящий поток может быть предоставлен, если программа в основном работает в узких циклах. Например, выполняет арифметику на больших матрицах или векторах. В этом слуае процессор корректно предскажет, что ветка в конце цикла будет достигнута почти во всех случаях. В итоге конвейер будет полным и процессор будет работать на полной скорости.

Однако, предположим, что мы имеем либо программу с большим количеством коротких циклов или объектно-ориентированную программу с большим количеством виртуальных объектов, которые могут ссылаться на реальные объекты, которые имеют различные реализации для часто вызываемых методов. В этих случаях сложно или даже невозможно для процессора предсказать какая ветка будет исполнена. Процессор, следовательно, вынужден либо простаивать, ожидая, что поток выполнения продвинется до момента, когда можно точно знать какая ветка будет исполнена, или догадываться. И для программ с непредсказуемым потоком управления - часто догадываться неправильно. Неправильные догадки могут быть очень дорогими, так как процессор вынужден выбросить все результаты инструкций, которые были выполнены спекулятивно. Более того, в независимости от того, простаивает процессор или догадывается, конвейер будет пустым и будет требовать наполнения. Это приведет к простоям, которые могут значительно уменьшить производительность, как ярко показано на графике 3.3. 

![Рисунок 3.3](../master/cartoons/pipeline.png?raw=true)

Рисунок 3.3 Процессор встречает сброс конвейера

К сожалению, сбросы конвейера не единственные опасности на дорожке с препятствиями, которые современный процессор обязан обойти. Следующий раздел описывает опасности получения данных из памяти.

## 3.1.2 Доступ к памяти

В 1980-х годах для микропроцессор часто мог загрузить значение из памяти быстрее, чем выполнить инструкцию. В 2006 году микропроцессор имеет возможность выполнять сотини или даже тысячи интсрукций за время единичного доступа к памяти. Это несоотвествие происходит из-за того, что закон Мура увеличил производительность процессоров с намного большей степенью, чем производительность памяти (стоит учитывать степень, с которой вырос размер памяти). Для примера, типичный компьютер 1970-x мог иметь 4 килобайта (да, килобайта, не мегабайта, не говоря уже о гигабайтах) оперативной памяти с однотактовым доступом. В 2008 проектировщики процессорров все еще могут создать 4 килобайтную память с однотактовым доступом, даже на системах с тактовами частотами в несолько гигагерц. И они часто создают такую память, только она теперь называется "кэш 0 уровня" и она довольно больше, чем 4 килобайта.

Несмотря на то что большие кэши, доступные на современных микропроцессорах, могут сделать довольно многое для борьбы с задержками доступа к памяти, для успешной работы они требуют высоко предсказуемых паттернов доступа. К сожалению, типичные операции, такие как обход связного списка, высоко непредсказуемы. В конце концов, если бы паттерны был предсказуемы, мы, программисты, не беспокоилсь бы об указателях, верно?

![Рисунок 3.4](../master/cartoons/memory-reference.png?raw=true)

Рисунок 3.4 Процессор встречает ссылку в памяти

Как видно из рисунка 3.4, ссылки на память часто являются серьезными препятствиями для современных процессоров.

До сих пор, мы рассматривали только препятствия, которые могут возникнуть во время исполнения процессором однопоточного кода. Мультипоточность представляется дополнительные препятсвия процессору, как описано в следующих разделах.

### 3.1.3 Атомарные операции

Одними их таких препятсвий являются атомарные операции. Сама идея атомарной операции в некотром роде конфликтует структурой "сборочной линии" современной процессорного конвеера. К чести проектировщиков аппаратного обеспечения, современные процессоры используют некоторые количестов крайне умных трюков, чтобы заставить эти операции *выглядеть* атомарными, даже несмотря на то, что они на самом дела выполняются по частям. Но даже так, все равно существуют случаи, когда конвеер обязан быть задержан или даже сброшен, для того чтобы определенная атомарная операциия выполнилась корректно. 

Итоговый эффект на производительность показан на рисунке 3.5.

![Рисунок 3.5](../master/cartoons/atomic-reference.png?raw=true)

Рисунок 3.5 Процессор встречает атомарную операцию

К содалению, атомарные операции обычно применяются только к одинарным частям данных. Так как многие параллельные алгоритмы требуют поддержки ограничений порядка выполнения между обновлениями нескольких элементов данных, то большинство процессоров предоставляют барьеры памяти. Эти барьеры также являются препятсвиями, который подрывают производительность, как описано в следующем разделе.

**Быстрый вопрос 3.2:** Какие типы машин разрешали бы атомарные операции над несколькими элементами данных?

К счастью, проектировщики процессоров сильно сфокусировались на атомарных операциях. Как итог, в начале 2012 года они сильно уменьшили (но, конечно, не исключили) накладные расходы этих операций.

### 3.1.4 Барьеры памяти

Барьеры памяти будут рассмотрены более глубоко в разделе 14.2 и приложении C. Сейчас же рассмотрим следующую простую критическую секции на основе лока.

```
1 spin_lock(&mylock);
2 a = a + 1;
3 spin_unlock(&mylock);
```

Если бы процессор не был ограничен в выполнение этих команд в том порядке, в котором они указаны, то переменная "a" могла бы быть инкрементирована без защиты локом "mylock". Это, без сомнения, разрушило бы весь смысл захвата лока. Для того, чтобы предотвратить столь разрушительные перестановки, блокировочные примитивы явно или неявно содержат барьеры памяти. Так как весь смысл этих барьеров в том, чтобы предовратить перестановки процессором команд с целью увеличения производительности, то барьеры памяти почти всегда ее ухудшают, что показано на рисунке 3.6.
 
Также как и с атомарными операциями, проектировщики аппаратного обеспечения много и упорно работали для того чтобы уменьшить накладные расходы барьеров памяти и добились в этом значимого прогресса.

![Рисунок 3.6](../master/cartoons/memory-barrier.png?raw=true)

Рисунок 3.6 Процессор встречает барьер памяти


### 3.1.5 Промахи кэша

Дополнительное мультипоточное препятствие для производительности процессоров  - это "промахи кэша". Как было указано ранее, современные процессоры поддерживаются большие кэши с целью уменьшить провалы по произодительности, вызванные высокой задержкой доступа к памяти. Однако, данные кэши в реальности контрпродуктивны для переменных, которые часто разделяются среди процессоров. Это происходит вследствие того что, когда процессор желает изменить переменную, вполне может произойти ситуация, при которой другой процессор недавно ее поменял. В этом случае переменная будет в кэше другого процессора (не первого), что, следовательно, приведет к дорогому промаху кэша (смотрите секцию C.1 для большей детализации). Такие промахи создают большое препятствие для производительности процессора, как показано на рисунке 3.7.

**Быстрый вопрос 3.3:** Действительно ли дизайнеры процессоров также сильно уменьшили накладные расходы промахов кэша?

![Рисунок 3.7](../master/cartoons/cpu-track-meet-cache-miss-toll-booth.png?raw=true)
*Tollbooth - пропускной пункт* 

Рисунок 3.7 Процессор промахивается мимо кэша
 
### 3.1.6 Операции ввода/вывода

Промах кэша можно воспринимать как операцию ввода/вывода между процессорами. И если рассматривать ее в этом виде, то это одна из наболее дешевых таких операциий. Операции ввода/вывода, включащие общение по сети, работу с диском или (что еще хуже) с людьми, ставят намного более большие препятствия, чем их внутренние аналоги, которые мы обсуждали в предыдущих разделах. Это показано на рисунке 3.8.  

![Рисунок 3.8](../master/cartoons/cpu-track-meet-phone-booth.png?raw=true)

**Голос** : *Пожалуйста, оставайтесь на линии. Ваш звонок очень важен для нас...*

Рисунок 3.8 Процессор ждет завершения операции ввода/вывода

Это одно из различий между параллелизмом в системах с разделяемой памятью и распеределенных системах. Системы с разделяемой памятью работают с препятствиями, не больше, чем  промаха кэша, в то время как распеределенные системы обычно несут с собой большие задержки сетевого взаимодействия. В обоих случаях, соответствующие задрежки могут воспрниматься как цена коммуникации - цену, которую не нужно бы было платить в последовательной программе. Следовательно, отношение между накладными расходами на коммуникации к реальной выполненной работе является ключевым параметром дизайна системы. Важная цель дизайна параллельного аппаратного обеспечения - это уменьшить это отношение настолько, чтобы достить соответсвтвующих целей по производительности и масштабируемости. В свою очередь, как мы увидим в главе 6, важная цель и дизайна параллельного программного обеспечения - это уменьшить частоту дорогих операций, таких как промах кэша.

Конечно, одно дело - это сказать, что оперция является препятствием, а другое - показать, что это операция является *значительным* препятствием. Это различие обсуждается в следующих разделах.

## 3.2 Накладные расходы

Этот раздел показывает актуальные накладные расходы препятствий для производительности, описанных в предущих разделах. Однако, для того, чтобы их понять, с начала необходимо получить грубый взгляд на аппаратную системную архитектуру. Это и является темой следующего раздела.

### 3.2.1 Системная архитектура аппартного обеспечения

Рисунок 3.9 показывает грубую схему 8-ядерной компьютерной системы. Каждая матрица имеет пару процессорных ядер, каждое со своим кэшем и шину, позволяющую процессорам общаться между собой. Системная шина в центре диаграммы позволяется четырем матрицам взаимодействовать между собой, а также соеденяет их с оперативной памятью.

![Рисунок 3.9](../master/images/cpu/system_arch.png?raw=true)

*Дистанция, которую проходит свет туда и обратно в вакууме для тактовой частоты 1.8 ГГц (8 см)*

Рисунок 3.9 Архитекутра системного аппартаного обеспечения

Данные передаются через эту систему блоками "кэш-линий", которые являются выравненными по степени 2 блоками фиксированного размера, обычно от 32 до 256 байт.
Когда процессор загружает переменную из памяти в один их своих регистров, он обязан загрузить кэш-линию, содержащую эту переменную, в свой кэш. Таким же образом, когда процессор сохраняет значение из одного из регистров в память, он обязан не только загрузить кэш-линию, но и удостоверится в том, что ни один другой процессор ни имеет ее копии.

Предположим, что процессор 0 выполняет операцию "сравнение с обменом" (compare-and-swap/CAS) на переменной, чья кэш-линия находится в кэше процессора 7. Упрощенная последовательность событий могла бы выглядеть так:

1. Процессор 0 проверяет локальный кэш и не находит кэш-линию.

2. Запрос перенаправляется к шине 0 и 1 процессоров, которая проверяет локальный кэш 1 процессора и не находит там кэш-линию.

3. Запрос перенаправляется к системной шине, которая проверяет 3 других матрицы и узнает, что кэш-линия держится матрицей с процессорами 6 и 7.

4. Запрос перенаправляется к шине 6 и 7 процессоров, которая проверяет их кэши и находит значение в кэше 7 процессора.

5. Процессор 8 передает кэш-линию к его шине и при этом сбрасывает ее из своего кэша.

6. Шина 6 и 7 процессоров передает кэш-линию системной шине.

7. Системная шина передает кэш-линию к шине 0 и 1 процессоров.

8. Шина 0 и 1 процессоров передает кэш-линию в кэш процессора 0.

9. Процессор 0 теперь может выполнить CAS операцию на значении из его кэша.

**Быстрый вопрос 3.4:** Это *упрощенная* последовательность событий? Как она вообще может быть более сложной?

**Быстрый вопрос 3.5:** Зачем необходимо сбрасывать кэш-линию из кэша процессора 7?


### 3.2.2 Цены операций

Накладные расходы некоторых типичных операций, важных для параллельных программ, показаны в таблице 3.1.

| Operation         | Cost (ns)   | Ratio       |
| ----------------- | -----------:| -----------:|
| Clock period      | 0.6         | 1.0         |
| Best-case CAS     | 37.9        | 63.2        |
| Best-case lock    | 65.6        | 109.3       |
| Single cache miss | 139.5       | 232.5       |
| CAS cache miss    | 306.0       | 510.0       |
| Comms Fabric      | 3,000       | 5,000       |
| Global Comms      | 130,000,000 | 216,000,000 |

Таблица 3.1 Производительность механизмов синхронизации на 4-процессорном 1.8 ГГц AMD Opteron 844

Сиcтемный такт примерно равен 0.6 нс. Хотя для современных микропроцессоров не редкость иметь возможность выполнять несколько инструкций за такт, операции будут нормализованы к целому такту в третьей колонке, названной "Коэффициент". 

Первая вещь, которую нужно заметить в этой таблице -это большие значения многих коэффициентов. В лучшем случае CAS операция занимает почти 40 наносекунд - время, почти в 60 раз превышающее тактовый цикл. Здесь под "лучшим случаем" понимается ситуация, когда процессор, который выполняет CAS операцию на переменной, является последним процессором, который к ней обращался и, следовательно, соотвествующая кэш-линия уже держится в кэше этого процессора. Похожим образом, лучший случай блокировки (пара, состоящая из захвата лока и его отпуска) занимает более 60 наносекунд или более 100 тактовых циклов. Опять же "лучший случай" значит, что структура данных, защищенная локом, уже находится в кэше процессора, которых захватывает и отпускает этот лок. Блокировка более дорога, чем CAS, потому что требуется две атомных операция на заблокированной структуре данных.

Операция, которая промахивается мимо кэша, занимает почти 140 наносекунд или более чем 200 тактовых циклов. Код, используемый для измерения промаха кэша, перекидывает кэш-линию между парой процессорв, таким образом, чтобы данные загружались не из основной памяти, а с кэша другого процессора. CAS операция, которая обязана найти старое значение переменной и сохранить новое, занимет почти 3000 наносекнуд, т.е более чем 5000 тактовых циклов. Подумайте немного об этом. За время, требуемое чтобы выполнить одну CAS операцию, процессор мог бы выолнить более 5000 обычных инструкций. Это показывает ограничение не только тонко-настроенной блокировки, но и любого другого механизма синхронизации, основанном на глобальном соглашении. 

**Быстрый вопрос 3.6:** Безусловно, разработчиков аппаратного обеспечения можно убедить улучшить эту ситуацию! Почему они мирятся с такой ужасной производительность для этих операций длиной в одну инструкцию?

Операции ввода/вывода еще более дороги. Высоко-производительные (и дорогие) фабрики коммуникаций, такие как InfiniBand или любые другие проприетарные шины, имеет задержку примерно в 3 микросекунды. За это время могли бы быть выполнены 5000 инструкций. При этом стандратные сети коммуникаций часто требуют некоторой обработки протокола, что в будущем увеличивает задержку. Конечно, географическое расстояние также увеличивает задержку. Теоретическая время обхода луча света вокруг земного шара составляет грубо 130 миллисекунд, или более чем 200 миллионов таковых циклов.

**Быстрый вопрос 3.7:** Эти цифры безумно огромны! Как я могу с ними справится?

Если коротко, то аппаратные и программные инжерены действительно воюют на одной стороне, пытаясь сделать компьютеры быстрее, несмотря на все усилия законов физики, как показано на рисунке 3.10, где наш поток данных пытается из всех усилий обогнать скорость света.

Следующий раздел обсуждает некоторые вещи, которые аппаратные инженеры мог ли бы (или не могли бы) сделать. Помощь программного обеспечения в этой схватке описана в оставшихся главах этой книги.

![Рисунок 3.10](../master/images/cpu/data_chasing_light_wave.png?raw=true)

*Быстрее! Быстрее!*

Рисунок 3.10 Программное и аппаратное обеспечение. На одной стороне.

## 3.3 Бесплатный обед "железа"? 

Главная причина, по которой конкурентность (concurrency) получает столько внимания в последние годы - это конец увеличения производительности по закону Мура (он же "бесплатный обед" [Sut08]), как показано на графике 2.1. Этот раздел быстро рассматривает несколько подходов, с помощью которых дизайнеры аппаратного обеспечения могли бы вернуть некоторую форму "бесплатного обеда".

Предыдущие раздела показали некоторые важные аппаратные препятствия при использовании конкурентности. Одно из жестких физических ограничений с которыми встречаются разработчики аппаратного обеспечения - это конечность скорости света. Как показано на рисунке 3.9, свет может проделать только 8-сантимеровый путь туда и обратно в вакууме за тактовой период в 1.8 ГГц. Это расстояние уменьшается только до 3 сантиметров для тактового периода в 5 ГГц. Оба этих расстояния относительны малы по сравнению с размером современной компьютерной системы.

Что еще хуже, электоны в кремние передвигаются от 3 до 30 раз медленнее, чем в вакууме, а типичные логические конструкции работет еще медленее. Например, ссылка на память может ожидать заверешение поиска в локальном кэше и только после этого запрос может быть передан остальной системе. Более того, для передачи электрических сигналов с одной кремниевой матрицы на другую требуются драйверы с относительно низкой скоростью и высокой мощностью. Например, они используются для коммуникации между процессором и оперативной памятью. 

**Быстрый вопрос 3.8:** Но отдельные электррны не перемещаются так быстро нигде, даже в проводниках! Скорость дрейфа электрона в проводнике на низких напряжениях, которая может быть найдена в полупроводниках, имеет величину порядка *миллиметра* в секунду. Где подвох?

Тем не менее существуют некоторые технологии (как аппаратные, так и программные), которые могут помочь улучшить эти вещи.

1. 3D интеграция;

2. Современные материалы и процессы;

3. Замена света на электроны;

4. Ускорители специального назначения;

5. Существующее параллельное программное обеспечение.

Каждая из этих технологий описана в следующих разделах.

### 3.3.1 3D интеграция

З-мерная интеграция (3DI) - это практика привязывания очень узких кремниевых матриц друг к другу в виде вертикального стека. Эта практика предоставляет потенциальные преимущества, но также и ставит значительныее производственные трудности [Kni08].

Возможно, наиболее важное преимущество 3DI - это уменьшенная длины пути через систему, как показано на рисунке 3.11. 3-сантиметровая кремнивая матрица заменяется стеком из 4-х 1.5 сантиметровых матриц, что в теории уменьшает максимальный путь через систему в 2 раза, если каждый уровень достаточно тонкий. К тому же, при должном внимании к проектированию и развертыванию, длинные горизонтальные элекрические соеденения(медленные и требующие большого количества энергии) могут быть заменены на короткие вертикальные электрические соеденения, которые быстры и более эффективны с точки зрения потребления мощности.

Однако, задежки из-за уровней тактовой логики не будут уменьшены с помощью 3D интеграции. При этом значительные проблемы производства, тестирования, поддержки питания и отвода тепла должны быть решены для 3D интеграции, чтобы достичь производства, все еще пологаясь на обещания. Проблемы отвода тепла могут быть решены с помощью полупроводников, помещенных на кристалл. Полупроводники являются хорошим проводником для тепла, но и в то же время диэлектриком. При этом остается трудным нарастить один большой кристалл, что уж говорить о том, чтобы наслоить их. В итоге, кажется очень маловероятным, что любая из технологий сможет приносить экспоненциальные увеличения производительности, к которым привыкли некоторые люди. Так что может быть необходимо ступить на дорожку вслед за Джим Греем "куря волосатые мячи для гольфа"/"smoking hairy golf balls" [Gra02]

### 3.3.2 Современные материалы и процессы

Говорят, что Стивен Хокинг заявлял, что производитель полупроводников имеют как минимум 2 фундаментальные проблемы:

1. Конеченая скорость света
2. Атомная структура материи

Возможно, что производитель полупроводников походят к этим пределам, но тем не менее существует несколько ветвей исследований и разработок, связанных с обходом этих фундаментальных проблем.

Один обходной путь для атомной структуры материи, это так называемые "высоко К-диэлектрированные" материалы, которые повзоляют большим устройствам повторять электрические свойства неразумных маленьких устройств. Эти материалы представляют некоторые тяжелые производственные трудности, но тем нее помогают продвинуться вперед. Другим обходным путем является сохранение нескольких битов в одном электроне, полагаясь на факт, что электрон может существовать на нескольких электрических уровнях. Оставется увидеть, как этот подход сможет работать надежно в производственных полупроводниковых устройствах.

Другой предпологаемый обходной путь - это подход с "квантовой точкой", который позволяет производить устройства более маленького размера. Но он все еще находится в стадии разработки.

### 3.3.3 Свет, а не электроны

Хотя скорость света и будет жестким ограничением, факт в том, что полупроводниковые устройства ограничены скорее скоростью электронов, нежели чем света. Это происходит, потому что электроны в полупроводниковых материалах перемещаются на уровне 3%-30% от скорости света в вакууме.
Использование медных соединений на кремниевых устройствах - один из способов увеличить скорость электронов. Вполне возможно, что дополнительные улучшения в этой области достигнут цифр, близких к действительной скорости света. Более того на основании того, что скорость света в стекле составляет примерно 60% скорости света в вакууме, производились некоторые эксперименты с тонкими оптоволокном в качестве шин между чипами. Одна из проблем в таких волокнах - это неэффективность преобразовании электричества в свет и наоборот, что приводит как к проблемам с потреблением мощности, так и отводом тепла.

Подытоживая, при отстуствии фундаментальных прорывов в физике, любое экспоненциальное увеличение скорости потока данных будет жестко ограничено действительной скоростью света в вакууме.

### 3.3.4 Ускорители специального назначения

Процессоры общего назначения, работающие над специализированными проблемами, часто тратят значительное количество времени и энергии, делая работу, которая только косвенно отновится к самой проблеме. Например, при вычислении скалярного произведения пары векторов, процессор общего назначения скорее всего использует цикл (возможно, раскрученный) со счетчиком. Декодировние инструкции, инкрементирование счетчика циклов, проверка счетчика и переход обратно к началу цикла - в некотором смысле пустая трата сил. Действительной целью процесса является умножение соотвествующих элементов двух векторов. Можно предположить, что специализированное аппаратное обеспечение, предназначенное специально для умножения векторов, могло бы сделать работу намного быстрее и меньшими затратами энергии.

Это в реальности является мотивацией для векторных инструкций, присутствующих во многих продуктовых микропроцессорах. Так как эти инструкции выполняются на нескольких элементах данных одновременно, они позволят скалярному произведению быть вычисленным с меньшими накладными расходами на декодирование инструкций и обработку циклов. 

Похожим образом, специализированное аппаратное обеспечение может эффективно шифровать и дешифровать, сжимать и разжимать, кодировать и декодировать, а так же многое другое. К сожалению, эта эффективность не достается бесплатно. Компьютерная система, используюшая специализированное аппаратное обеспечение, будет содержать большее количество транзисторов, которые будет потреблять больше мощности, даже когда они не используются. Программное обеспечение обязано быть изменено для использования преимуществ такого "железа". При этом, для чтобы быть доступным, аппаратное обеспечение обязано быть достаточно полезным, чтобы высокая начальная цена проектирования могла быть распространена на достаточное количество пользователей. Отчасти засчет таких экономических соображений, такое "железо" появилось только в нескольких прикладных областях, включая обработку графики (GPU), векторов (MMX, SSE и VMX инструкции) и, в некоторой степени, шифровании.

В отличие от серверов и персональных компьютеров, смартфоны давно использовали и используют широкий спектр аппаратных ускорителей. Они часто используются для декодирования медиафайлов, таким образом чтобы качественный MP3-плеер мог играть аудиодорожку несколько минут при полном отключении процессора за все время проигрывания. Цель этих ускорителей - улучшить энергетическую эффективность и, следовательно, продлить жизнь батареи. Специализированное аппаратное обеспечение может часто вычислять более эффективно, чем процессор общего назначения. Это один из примеров принципа, показанного в разделе 2.2.3: Общность почти никода не достается бесплатно.

Тем не менее, учитывая конец увеличения однопоточной производительности по закону Мура, смотрится безопасным предположить, что в ближайшее время произойдет увеличиние количества различного аппаратного обеспечения специального назначения.

### 3.3.5 Существующее параллельное программное обеспечение

Хотя мультиядерные процессоры пришли в компьютерную индустрию внезапно, остает фактом, что параллельные системы с разделяемой памятью были коммерчески доступны более чем 25 лет. Это более чем достаточный срок для появления значительного параллельного программного обеспечение, и оно действительно появилосб. Параллельные операционные системы вполне обычны как и параллельные библиотеки работы с потоками, параллельные системы управления базами данных и параллельное вычислительное программное обеспечение. Использование существующего параллельное программного обеспечения может пройти долгий путь до любого кризиса, с которым мы можем столкнуться.

Возможно, самый типичный пример - это праллельные системы управления базами данных. Вполне обычная ситуация, когда однопоточнын программы, написанные на высокоуровнех скриптовых языках, работают с центральной базой данных конкурентно. В конечной высокопараллельной системе, только база данных в должна работать с параллелизмом. Очень красивый трюк, когда работает!


























