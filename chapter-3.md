# Глава 3

## Аппаратное обеспечение и его повадки

Большинство людей имеют интуитивное понимание того, что передача сообщений между системами более дороже, чем выполнение простых вычислений в рамках одной системы. Однако, не всегда ясно, что коммуникация между потоками в рамках одной системы с разделенной памятью может быть тоже вполне дорогой. Эта глава рассматривает цену синхронизации и коммуникации в рамках такой системы. Эти несколько страниц все лишь покажут вершину айсберга дизайна параллельного аппаратного обеспечения с разделенной памятью. Читатели, желающие получить больше деталей, могут начать с последного издания классической книги Хеннесси и Паттерсона [HP95].

**Быстрый вопрос 3.1:**  Зачем программистам параллельных систем учить низкоуровненевые свойства аппартаного обеспечения? Не будет ли проще, лучше, и более обще отстаться на более высоком уровне абстракции?

## 3.1 Обзор

Беззаботные читатели спецификаций компьютерных систем могут прийти к выводу, что производительность процессоров и забег на чистой дороге, как показано на графике 3.1, где победу всегда одерживает быстрейший.

![График 3.1](../master/cartoons/trackmeet.png?raw=true)

График 3.1 Производительность процессоров в забеге

Хотя есть несколько процессорных бенчмарков, которые берут за основу идеал, показанный на графике, реальные программы больше похожы на бег с препятствиями, чем на забег по дорожкам. Это происходит из-за внутренней архитектуры процессоров, которая сильно изменилась за последние несколько десятков лет благодаря закону Мура. Эти изменения показаны в следующих разделах.

### 3.1.1 Конвейерные процессоры

Как работал в начале 1980-х типичный микропроцессор: он выбирал инструкцию, декодировал ее и затем выполнял. В итоге требовалось *как минимум* 3 такта, чтобы обработать одну инструкцию перед переходом к следующей. На контрасте, типичный процессор конца 1990-х - начала 2000-х выполнят много инструкций одновременно, используя глубокий "конвейер" для управления потоком инструкций внутри процессора. Эти современные аппаратные возможности могут сильно улучшить производительность, как показано на графике 3.2.

![График 3.2](../master/cartoons/old_man_and_brat.png?raw=true)

**Новый** : *4.0 Гц тактовая частота, 20 Мб кэша 3 уровня, 20 уровненый конвейер*

**Старый**: *Единственный конвейер который мне нужен, это тот, который остудит этого горячего молокососа*

График 3.2 Старый и новый процессор

Достижение полной производительности с процессором, который имеет длинный конвейер, требует высокопредсказуемого потока управления во время программы. Подходящий поток может быть предоставлен, если программа в основном работает в узких циклах. Например, выполняет арифметику на больших матрицах или векторах. В этом слуае процессор корректно предскажет, что ветка в конце цикла будет достигнута почти во всех случаях. В итоге конвейер будет полным и процессор будет работать на полной скорости.

Однако, предположим, что мы имеем либо программу с большим количеством коротких циклов или объектно-ориентированную программу с большим количеством виртуальных объектов, которые могут ссылаться на реальные объекты, которые имеют различные реализации для часто вызываемых методов. В этих случаях сложно или даже невозможно для процессора предсказать какая ветка будет исполнена. Процессор, следовательно, вынужден либо простаивать, ожидая, что поток выполнения продвинется до момента, когда можно точно знать какая ветка будет исполнена, или догадываться. И для программ с непредсказуемым потоком управления - часто догадываться неправильно. Неправильные догадки могут быть очень дорогими, так как процессор вынужден выбросить все результаты инструкций, которые были выполнены спекулятивно. Более того, в независимости от того, простаивает процессор или догадывается, конвейер будет пустым и будет требовать наполнения. Это приведет к простоям, которые могут значительно уменьшить производительность, как ярко показано на графике 3.3. 

![Рисунок 3.3](../master/cartoons/pipeline.png?raw=true)

Рисунок 3.3 Процессор встречает сброс конвейера

К сожалению, сбросы конвейера не единственные опасности на дорожке с препятствиями, которые современный процессор обязан обойти. Следующий раздел описывает опасности получения данных из памяти.

## 3.1.2 Доступ к памяти

В 1980-х годах для микропроцессор часто мог загрузить значение из памяти быстрее, чем выполнить инструкцию. В 2006 году микропроцессор имеет возможность выполнять сотини или даже тысячи интсрукций за время единичного доступа к памяти. Это несоотвествие происходит из-за того, что закон Мура увеличил производительность процессоров с намного большей степенью, чем производительность памяти (стоит учитывать степень, с которой вырос размер памяти). Для примера, типичный компьютер 1970-x мог иметь 4 килобайта (да, килобайта, не мегабайта, не говоря уже о гигабайтах) оперативной памяти с однотактовым доступом. В 2008 проектировщики процессорров все еще могут создать 4 килобайтную память с однотактовым доступом, даже на системах с тактовами частотами в несолько гигагерц. И они часто создают такую память, только она теперь называется "кэш 0 уровня" и она довольно больше, чем 4 килобайта.

Несмотря на то что большие кэши, доступные на современных микропроцессорах, могут сделать довольно многое для борьбы с задержками доступа к памяти, для успешной работы они требуют высоко предсказуемых паттернов доступа. К сожалению, типичные операции, такие как обход связного списка, высоко непредсказуемы. В конце концов, если бы паттерны был предсказуемы, мы, программисты, не беспокоилсь бы об указателях, верно?

![Рисунок 3.4](../master/cartoons/memory-reference.png?raw=true)

Рисунок 3.4 Процессор встречает ссылку в памяти

Как видно из рисунка 3.4, ссылки на память часто являются серьезными препятствиями для современных процессоров.

До сих пор, мы рассматривали только препятствия, которые могут возникнуть во время исполнения процессором однопоточного кода. Мультипоточность представляется дополнительные препятсвия процессору, как описано в следующих разделах.

### 3.1.3 Атомарные операции

Одними их таких препятсвий являются атомарные операции. Сама идея атомарной операции в некотром роде конфликтует структурой "сборочной линии" современной процессорного конвеера. К чести проектировщиков аппаратного обеспечения, современные процессоры используют некоторые количестов крайне умных трюков, чтобы заставить эти операции *выглядеть* атомарными, даже несмотря на то, что они на самом дела выполняются по частям. Но даже так, все равно существуют случаи, когда конвеер обязан быть задержан или даже сброшен, для того чтобы определенная атомарная операциия выполнилась корректно. 

Итоговый эффект на производительность показан на рисунке 3.5.

![Рисунок 3.5](../master/cartoons/atomic-reference.png?raw=true)

Рисунок 3.5 Процессор встречает атомарную операцию

К содалению, атомарные операции обычно применяются только к одинарным частям данных. Так как многие параллельные алгоритмы требуют поддержки ограничений порядка выполнения между обновлениями нескольких элементов данных, то большинство процессоров предоставляют барьеры памяти. Эти барьеры также являются препятсвиями, который подрывают производительность, как описано в следующем разделе.

**Быстрый вопрос 3.2:** Какие типы машин разрешали бы атомарные операции над несколькими элементами данных?

К счастью, проектировщики процессоров сильно сфокусировались на атомарных операциях. Как итог, в начале 2012 года они сильно уменьшили (но, конечно, не исключили) накладные расходы этих операций.

### 3.1.4 Барьеры памяти

Барьеры памяти будут рассмотрены более глубоко в разделе 14.2 и приложении C. Сейчас же рассмотрим следующую простую критическую секции на основе лока.

```
1 spin_lock(&mylock);
2 a = a + 1;
3 spin_unlock(&mylock);
```

Если бы процессор не был ограничен в выполнение этих команд в том порядке, в котором они указаны, то переменная "a" могла бы быть инкрементирована без защиты локом "mylock". Это, без сомнения, разрушило бы весь смысл захвата лока. Для того, чтобы предотвратить столь разрушительные перестановки, блокировочные примитивы явно или неявно содержат барьеры памяти. Так как весь смысл этих барьеров в том, чтобы предовратить перестановки процессором команд с целью увеличения производительности, то барьеры памяти почти всегда ее ухудшают, что показано на рисунке 3.6.
 
Также как и с атомарными операциями, проектировщики аппаратного обеспечения много и упорно работали для того чтобы уменьшить накладные расходы барьеров памяти и добились в этом значимого прогресса.

![Рисунок 3.6](../master/cartoons/memory-barrier.png?raw=true)

Рисунок 3.6 Процессор встречает барьер памяти


### 3.1.5 Промахи кэша

Дополнительное мультипоточное препятствие для производительности процессоров  - это "промахи кэша". Как было указано ранее, современные процессоры поддерживаются большие кэши с целью уменьшить провалы по произодительности, вызванные высокой задержкой доступа к памяти. Однако, данные кэши в реальности контрпродуктивны для переменных, которые часто разделяются среди процессоров. Это происходит вследствие того что, когда процессор желает изменить переменную, вполне может произойти ситуация, при которой другой процессор недавно ее поменял. В этом случае переменная будет в кэше другого процессора (не первого), что, следовательно, приведет к дорогому промаху кэша (смотрите секцию C.1 для большей детализации). Такие промахи создают большое препятствие для производительности процессора, как показано на рисунке 3.7.

**Быстрый вопрос 3.3:** Действительно ли дизайнеры процессоров также сильно уменьшили накладные расходы промахов кэша?

![Рисунок 3.7](../master/cartoons/cpu-track-meet-cache-miss-toll-booth.png?raw=true)
*Tollbooth - пропускной пункт* 

Рисунок 3.7 Процессор промахивается мимо кэша
 
### 3.1.6 Операции ввода/вывода

Промах кэша можно воспринимать как операцию ввода/вывода между процессорами. И если рассматривать ее в этом виде, то это одна из наболее дешевых таких операциий. Операции ввода/вывода, включащие общение по сети, работу с диском или (что еще хуже) с людьми, ставят намного более большие препятствия, чем их внутренние аналоги, которые мы обсуждали в предыдущих разделах. Это показано на рисунке 3.8.  

![Рисунок 3.8](../master/cartoons/cpu-track-meet-phone-booth.png?raw=true)

**Голос** : *Пожалуйста, оставайтесь на линии. Ваш звонок очень важен для нас...*

Рисунок 3.8 Процессор ждет завершения операции ввода/вывода

Это одно из различий между параллелизмом в системах с разделяемой памятью и распеределенных системах. Системы с разделяемой памятью работают с препятствиями, не больше, чем  промаха кэша, в то время как распеределенные системы обычно несут с собой большие задержки сетевого взаимодействия. В обоих случаях, соответствующие задрежки могут воспрниматься как цена коммуникации - цену, которую не нужно бы было платить в последовательной программе. Следовательно, отношение между накладными расходами на коммуникации к реальной выполненной работе является ключевым параметром дизайна системы. Важная цель дизайна параллельного аппаратного обеспечения - это уменьшить это отношение настолько, чтобы достить соответсвтвующих целей по производительности и масштабируемости. В свою очередь, как мы увидим в главе 6, важная цель и дизайна параллельного программного обеспечения - это уменьшить частоту дорогих операций, таких как промах кэша.

Конечно, одно дело - это сказать, что оперция является препятствием, а другое - показать, что это операция является *значительным* препятствием. Это различие обсуждается в следующих разделах.

## 3.2 Накладные расходы

Этот раздел показывает актуальные накладные расходы препятствий для производительности, описанных в предущих разделах. Однако, для того, чтобы их понять, с начала необходимо получить грубый взгляд на аппаратную системную архитектуру. Это и является темой следующего раздела.

### 3.2.1 Системная архитектура аппартного обеспечения

Рисунок 3.9 показывает грубую схему 8-ядерной компьютерной системы. Каждая матрица имеет пару процессорных ядер, каждое со своим кэшем и шину, позволяющую процессорам общаться между собой. Системная шина в центре диаграммы позволяется четырем матрицам взаимодействовать между собой, а также соеденяет их с оперативной памятью.

![Рисунок 3.9](../master/images/cpu/system_arch.png?raw=true)

*Дистанция, которую проходит свет туда и обратно в вакууме для тактовой частоты 1.8 ГГц (8 см)*

Рисунок 3.9 Архитекутра системного аппартаного обеспечения

Данные передаются через эту систему блоками "кэш-линий", которые являются выравненными по степени 2 блоками фиксированного размера, обычно от 32 до 256 байт.
Когда процессор загружает переменную из памяти в один их своих регистров, он обязан загрузить кэш-линию, содержащую эту переменную, в свой кэш. Таким же образом, когда процессор сохраняет значение из одного из регистров в память, он обязан не только загрузить кэш-линию, но и удостоверится в том, что ни один другой процессор ни имеет ее копии.

Предположим, что процессор 0 выполняет операцию "сравнение с обменом" (compare-and-swap/CAS) на переменной, чья кэш-линия находится в кэше процессора 7. Упрощенная последовательность событий могла бы выглядеть так:

1. Процессор 0 проверяет локальный кэш и не находит кэш-линию.

2. Запрос перенаправляется к шине 0 и 1 процессоров, которая проверяет локальный кэш 1 процессора и не находит там кэш-линию.

3. Запрос перенаправляется к системной шине, которая проверяет 3 других матрицы и узнает, что кэш-линия держится матрицей с процессорами 6 и 7.

4. Запрос перенаправляется к шине 6 и 7 процессоров, которая проверяет их кэши и находит значение в кэше 7 процессора.

5. Процессор 8 передает кэш-линию к его шине и при этом сбрасывает ее из своего кэша.

6. Шина 6 и 7 процессоров передает кэш-линию системной шине.

7. Системная шина передает кэш-линию к шине 0 и 1 процессоров.

8. Шина 0 и 1 процессоров передает кэш-линию в кэш процессора 0.

9. Процессор 0 теперь может выполнить CAS операцию на значении из его кэша.

**Быстрый вопрос 3.4:** Это *упрощенная* последовательность событий? Как она вообще может быть более сложной?

**Быстрый вопрос 3.5:** Зачем необходимо сбрасывать кэш-линию из кэша процессора 7?


### 3.2.2 Цены операций

Накладные расходы некоторых типичных операций, важных для параллельных программ, показаны в таблице 3.1.

| Operation         | Cost (ns)   | Ratio       |
| ----------------- | -----------:| -----------:|
| Clock period      | 0.6         | 1.0         |
| Best-case CAS     | 37.9        | 63.2        |
| Best-case lock    | 65.6        | 109.3       |
| Single cache miss | 139.5       | 232.5       |
| CAS cache miss    | 306.0       | 510.0       |
| Comms Fabric      | 3,000       | 5,000       |
| Global Comms      | 130,000,000 | 216,000,000 |

Таблица 3.1 Производительность механизмов синхронизации на 4-процессорном 1.8 ГГц AMD Opteron 844

Сиcтемный такт примерно равен 0.6 нс. Хотя для современных микропроцессоров не редкость иметь возможность выполнять несколько инструкций за такт, операции будут нормализованы к целому такту в третьей колонке, названной "Коэффициент". 

Первая вещь, которую нужно заметить в этой таблице -это большие значения многих коэффициентов. В лучшем случае CAS операция занимает почти 40 наносекунд - время, почти в 60 раз превышающее тактовый цикл. Здесь под "лучшим случаем" понимается ситуация, когда процессор, который выполняет CAS операцию на переменной, является последним процессором, который к ней обращался и, следовательно, соотвествующая кэш-линия уже держится в кэше этого процессора. Похожим образом, лучший случай блокировки (пара, состоящая из захвата лока и его отпуска) занимает более 60 наносекунд или более 100 тактовых циклов. Опять же "лучший случай" значит, что структура данных, защищенная локом, уже находится в кэше процессора, которых захватывает и отпускает этот лок. Блокировка более дорога, чем CAS, потому что требуется две атомных операция на заблокированной структуре данных.

Операция, которая промахивается мимо кэша, занимает почти 140 наносекунд или более чем 200 тактовых циклов. Код, используемый для измерения промаха кэша, перекидывает кэш-линию между парой процессорв, таким образом, чтобы данные загружались не из основной памяти, а с кэша другого процессора. CAS операция, которая обязана найти старое значение переменной и сохранить новое, занимет почти 3000 наносекнуд, т.е более чем 5000 тактовых циклов. Подумайте немного об этом. За время, требуемое чтобы выполнить одну CAS операцию, процессор мог бы выолнить более 5000 обычных инструкций. Это показывает ограничение не только тонко-настроенной блокировки, но и любого другого механизма синхронизации, основанном на глобальном соглашении. 

**Быстрый вопрос 3.6:** Безусловно, разработчиков аппаратного обеспечения можно убедить улучшить эту ситуацию! Почему они мирятся с такой ужасной производительность для этих операций длиной в одну инструкцию?

Операции ввода/вывода еще более дороги. Высоко-производительные (и дорогие) фабрики коммуникаций, такие как InfiniBand или любые другие проприетарные шины, имеет задержку примерно в 3 микросекунды. За это время могли бы быть выполнены 5000 инструкций. При этом стандратные сети коммуникаций часто требуют некоторой обработки протокола, что в будущем увеличивает задержку. Конечно, географическое расстояние также увеличивает задержку. Теоретическая время обхода луча света вокруг земного шара составляет грубо 130 миллисекунд, или более чем 200 миллионов таковых циклов.

**Быстрый вопрос 3.7:** Эти цифры безумно огромны! Как я могу с ними справится?

Если коротко, то аппаратные и программные инжерены действительно воюют на одной стороне, пытаясь сделать компьютеры быстрее, несмотря на все усилия законов физики, как показано на рисунке 3.10, где наш поток данных пытается из всех усилий обогнать скорость света.

Следующий раздел обсуждает некоторые вещи, которые аппаратные инженеры мог ли бы (или не могли бы) сделать. Помощь программного обеспечения в этой схватке описана в оставшихся главах этой книги.

![Рисунок 3.10](../master/images/cpu/data_chasing_light_wave.png?raw=true)

*Быстрее! Быстрее!*

Рисунок 3.10 Программное и аппаратное обеспечение. На одной стороне.

## 3.3 Бесплатный обед "железа"? 

Главная причина, по которой конкурентность (concurrency) получает столько внимания в последние годы - это конец увеличения производительности по закону Мура (он же "бесплатный обед" [Sut08]), как показано на графике 2.1. Этот раздел быстро рассматривает несколько подходов, с помощью которых дизайнеры аппаратного обеспечения могли бы вернуть некоторую форму "бесплатного обеда".

Предыдущие раздела показали некоторые важные аппаратные препятствия при использовании конкурентности. Одно из жестких физических ограничений с которыми встречаются разработчики аппаратного обеспечения - это конечность скорости света. Как показано на рисунке 3.9, свет может проделать только 8-сантимеровый путь туда и обратно в вакууме за тактовой период в 1.8 ГГц. Это расстояние уменьшается только до 3 сантиметров для тактового периода в 5 ГГц. Оба этих расстояния относительны малы по сравнению с размером современной компьютерной системы.

Что еще хуже, электоны в кремние передвигаются от 3 до 30 раз медленнее, чем в вакууме, а типичные логические конструкции работет еще медленее. Например, ссылка на память может ожидать заверешение поиска в локальном кэше и только после этого запрос может быть передан остальной системе. Более того, для передачи электрических сигналов с одной кремниевой матрицы на другую требуются драйверы с относительно низкой скоростью и высокой мощностью. Например, они используются для коммуникации между процессором и оперативной памятью. 

**Быстрый вопрос 3.8:** Но отдельные электррны не перемещаются так быстро нигде, даже в проводниках! Скорость дрейфа электрона в проводнике на низких напряжениях, которая может быть найдена в полупроводниках, имеет величину порядка *миллиметра* в секунду. Где подвох?

Тем не менее существуют некоторые технологии (как аппаратные, так и программные), которые могут помочь улучшить эти вещи.

1. 3D интеграция;

2. Современные материалы и процессы;

3. Замена света на электроны;

4. Ускорители специального назначения;

5. Существующее параллельное программное обеспечение.

Каждая из этих технологий описана в следующих разделах.
