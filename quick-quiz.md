# Ответы на Быстрые вопросы

## F.2 Введение  

### Быстрый вопрос 2.1

*Ну хватит!! Параллельное программирование было невообразимо сложным многие десятилетия. Вы же, судя по всему, указываете на то, что оно не так сложно. На что вы намекаете?*

**Ответ**

Если вы действительно верите, что параллельное программирование невообразимо сложно, то значит, что у вас есть готовый ответ на вопрос "Почему параллельное программирование тяжело?". Можно привести любое количество причин, начиная от дедлоков до гонок условий и покрытия тестами, но реалистичный ответ на этот вопрос: *"В действительности параллельное программирование не полностью так сложно"*. В конце концов, если бы оно было таким ужасно сложным, как большое количество проектов с открытым исходным кодом, начиная от Apache и MySQL и заканчивая ядром Linux, смогли с ним управится?

Более правильный вопрос мог бы быть таким: "Почему параллельное программрование имеет репутацию такой сложной дисциплины?". Для того чтобы увидеть ответ, вернемся в 1991 год. Пол МакКенни переходил парковку в Sequent центре бенчмарков, неся с собой 6 симметричных материнских плат Sequent с поддержкой двух процессоров 80486, когда он внезапно осознал, что он несет с собой сумму, в несколько раз превышающую цену дома, который он только что купил. Высокая цена параллельных систем означала, что параллельное программирование было доступно только для тех привелигированных, кто работал либо на работадателя, который производил такие машины или того, который имел возможность приобрести их. А цена на них начиналась со 100,000 долларов (доллар 1991 года).

На контрасте с этим в 2006 году Пол пишет эти слова на двухядерном x86 ноутбуке. В отличие от платы, этот ноутбук также имеет 2 Гб оперативной памяти, 60 Гб диска, экран, сеть, USB порты, Wi-Fi и Bluetooth. И этот ноутбук более чем на порядок дешевле, чем каждая из этих плат. Даже если учитывать инфляцию.

Параллельные системы действительно пришли в рельность. Они больше не привелегия для избранных, а вещь, доступная практически каждому.

Ограниченная доступность параллельного аппаратного обеспечения в прошлом действительно *реальная* причина, почему параллельное программирование рассматривалось как тяжелая дисциплина. В конце концов, достаточно сложно научится программировать даже на самой простой машине, если у вас нет к ней доступа. Так как век редких и дорогих параллельных машин в большинстве своем уже прошел, то уходит и век, в котором параллельное программирование рассматривалось как область, "выносящая мозг" по своей сложности. 


### Быстрый вопрос 2.2: 

*Как параллельное программирование вообще может быть таким же легким, как последовательное программирование?*

**Ответ:** 

Это зависит от программной среды. SQL[Int92] - это неоцененная история успеха. Он позволяет программистам, которые ничего не знают о параллизме, нагружать большие параллельные системы полезной работой. Мы можем ожидать больше похожих историй по мере того как параллельные компьютеры становятся все дешевле и доступнее. Например, один из возможных претендетов в области научных и технических вычислений - это MATLAB*P, который пытается автоматически параллелизировать типичные матричные операции.

Расмотрите следующую shell команду в Linux и UNIX системах:

`get_input | grep "interesting" | sort`

Этот пайп запускает *get_input*, *grep* и *sort* процессы параллельно. Это же не было так сложно?

Короче говоря, параллельное программирование также просто как последовательное программирование, по крайней мере в тех средах, которые скрывают параллизм от пользователя!


### Быстрый вопрос 2.3: 

*Серьезно? А что насчет корректности, поддерживаемости, надежности и так далее?*

**Ответ:**

Это тоже важные цели, но они важны и для последовательных программ также как для параллельных. Следовательно, какими бы важными они не были, они не входят в список проблем, специфичиных для параллельного программирования.


### Быстрый вопрос 2.4: 

*И если корректность, поддерживаемость и надежность не попали в список, почему попали эффективность и общность?*

**Ответ:**

Учитывая, что параллельное программирование воспринимается как более тяжелое программирование, чем последовательное, эффективность так же важна и не может быть опущена. Хотя высокоэффективные среды параллельного программирования, такие как SQL, выполняют специальную задачу, общность также обязана быть добавлена в список.

### Быстрый вопрос 2.5: 

*Учитывая, что намного сложнее доказать корректность параллельных программ, чем последовательных, опять, не должна ли все-таки корректность быть в списке?*

**Ответ:**

С инжереной точки зрения, сложность доказательства корректности - формально или неформально - будет важна только, когда она влияет на главную цель эффективности. Таким образом, в случаях, когда доказательства корректности важны, они включается под рубрикой "эффективность"

### Быстрый вопрос 2.6: 

*Как насчет того, чтобы просто весело проводить время?*

**Ответ:**

Весело проводить время тоже важно. Но если вы не любитель, это не должно быть *главной* целью. Впрочем, если вы все-таки любитель, не сдерживайте себя!

### Быстрый вопрос 2.7: 

*Разве не существует ситуаций, когда параллельное программирование - это не о производительности?*

**Ответ:**

Конечно, существуют случаи, когда проблемы по своей природе могут быть решены с помощью параллелизма. Например, методы Монте-Карло и некоторые числовые вычисления. Однако, даже в этих случаях всегда будет некоторое количество дополнительной работы по управлению параллелизмом.

Параллелизм также иногда используется для надежности. Как пример, трех-модульное резервирование использует три системы, запущенные параллельно и голосует при выборе результата. В крайних случаях, эти три системы могут быть независимо реализованы с использованием разных алгоримтов и технологий.

### Быстрый вопрос 2.8: 

*Зачем нужна вся эта болтовня о нетехнических вопросах? И не только о нетехнических вопросах, а и об эффективности всех этих вещей? Кого это волнует?*

**Ответ:**

Если вы чистый любитель, возможно вас это не волнует. Но даже чистые любители будут часто волноваться по поводу, сколько они сделали и как быстро. В конце концов, наиболее популярные инструменты для любителей это те, которые лучше всего подходят для их работы. И важная часть определения "лучше всего подходят" включает эффективность. Ну а если кто-то платит вам за то, что вы пишете параллельный код, они будут очень сильно волноваться о вашей эффективности. И если человек, который платит вам, беспокоится о чем-нибудь, то будет вполне мудро обратить хоть немного внимания на это!

Кроме того, если бы вы действительно не беспокоились об эффективности, вы бы делали вещи руками, а не с помощью компьютера!

### Быстрый вопрос 2.9: 

*Учитывая насколько дешевыми стали параллельные системы, как люди могут позволить платить программистам, работающими с этими системами?*

**Ответ:**

Имеется несколько ответов на этот вопрос:

1. Для большого кластера параллельных машин, общая цена кластера может быть легко оправдана с помощью усилий разработчиков, потому что цена разработки может быть распределена на большое количество машин.

2. Популярное программное обеспечение, которое запускают десятки миллионов пользователей, легко оправдывает цену разработки, потому что эта цена распределена среди пользователей. Учтите, что это включает вещи типа ядер операционных систем и системных библиотек.

3. Если дешевая параллельная машина контролирует работу значимой части оборудования, то цена работы этой части легко опрадывает затраченные усилия разработчиков.

4. Если программное обеспечение, работающее на дешевой параллельной машине предоставляет очень важный результат, то этот результат может оправдать цену разработки.

5. Критичные по безопасности системы защищают жизни, что явно оправдывает очень большие усилия разработчиков.

6. Любители и исследователи могут искать знание, опыт, развлечение или славу вместо золота.

Следовательно, уменьшающаяся цена аппаратного обеспечения не делает программное обеспечение "неценным". Теперь, скорее, невозможно "скрывать" цену разработки ПО за ценой "железа". Исключениями могут являться случаи, имеется огромное количество этого "железа".

### Быстрый вопрос 2.10: 

*Это до смешного недостижимая цель! Почему бы не сфокусироваться на чем-нибудь более достижимом на практике?*

**Ответ:**

Конечно, это достижимо. Мобильный телефон - это компьютер, который может быть использован для того, чтобы делать звонки, отправлять и получать текстовые сообщения с небольшими усилями (или вообще их отсутствию) по программированию и конфигурации для конечного пользователя.

Это может смотрется как тривильный пример на первый взгляд, но если вы рассмотрите его пристально, то увидите что это просто и красиво. Когда мы можем принебречь общностью, мо можем достичь действительно впечатляющих улучшений в эффективности. Те же, кто хочет достичь дополнительной общности, будут вынуждены понизить планку эффективности для успеха на верхних уровнях стека программного обеспечения. Этот жизненный факт даже имеет собственный акроним: YAGNI или "You Ain't Gonna Need It" - "Тебе это не нужно".


### Быстрый вопрос 2.11:  

*Какие другие "бутылочные горлышки" могут предотвратить увеличение производительности от добавления процессоров?*

**Ответ:**

Имеется несколько потенциальных "бутылычных горлышек":

1. Оперативная память. Если один поток потребляет всю доступную память, добавление дополнительных потоков только уведет их в подкачку.

2. Кэш. Если полезные данные одного потока полностью заполняют все общие кэши процессоров, то добавление дополнительных потоков просто разобьет эти кэши.

3. Пропускная способность памяти. Если один поток использует все пропускную способность памяти, то добавление дополнительных потоков выльется в ожидание в очередях на системных шинах.

4. Пропуская способность ввода/вывода. Если один поток ограничен по вводу/выводу, то добавление дополнительных потоков выльется в ожидание в очереди на использование "горячего" устройства ввода/вывода.

Специфичное аппаратное обеспечение может иметь любое количество дополнительных "бутылычных горлышек". Факт в том, что каждый ресурс, который распределяется между несколькими процессорами, является потенциальной проблемой.

### Быстрый вопрос 2.12: 

*Кроме размера кэшей процессоров, что еще может ограничивать количество одновременно выполняющихся потоков?*

**Ответ:**

Есть несколько потенциальных ограничений на количество потоков:

1. Оперативная память. Каждый поток потребляет некоторое количество памяти (хотя бы на стек). Следовательно, излишнее количество потоков может съесть всю память, что выльется в излишее количество переносов страниц памяти в подкачку или ошибки выделения памяти.

2. Пропускная способность ввода/вывода. Если каждый поток выполняет некоторое количество работы с внутренним вводом/выводом или сетью, то излишнее количество потоков может вызвать излишние задержки на устройствах ввода/вывода, что уменьшает производительность. Некоторые сетевые протоколы могут прерывать запросы по таймауту или выбрасывать ошибки, потому что они(запросы) не могут быть обработаны за короткий интервал времени.

3. Дополнительные расходы на синхронизацию. Для многих протоколов синхронизации излишнее количество потоков может выльется в излишние попытки захватить состояние в цикле, блокировки, откаты и т.д, что ухудшает производительность.

Специфичные приложения и платформы могут иметь любое количество дополнительных факторов.

### Быстрый вопрос 2.13:

*Существуют ли другие препятствия в параллельном программировании?*  

**Ответ:**

Существует большое количество потенциальных препятствий в параллельном программировании. Вот, например, одни из них:

1. Единственные известные алгоритмы для конкретного проекта могут быть по своей сути последовательными. В этом случае, лучше либо избегать параллельного программирования (нет закона, который говорит о том, что ваш проект обязан его использовать) или изобрести новый параллельный алгоритм.

2. Проект использует плагинную архитектуру. Плагины подключаются к ядру (шине) и разделяют общее адресное пространство. В этом случае ни один разработчик не имеет доступ к полному исходному коду проекта. Так как большинство параллельных багов, включая дедлоки, глобальны по своей природе, такая архитектура является тяжелым испытанием для текущих методологий разработки программного обеспечения. Это может изменится в будущем, но сейчас все разработчики параллельного кода, разделяющего общее адресное пространство, должны иметь необходимость увидеть *весь* код, который запускается в этом пространстве.

3. Проект сильно использует API, которые не были спроектрованы с учетом параллелизма [AGH11a, CKZ13]. Как пример можно привести некоторые места в API брокера сообщений System V. Если ваш проект работает несолько десятков дет и его разработчики не имели доступа к параллельному аппаратному обеспечению, вы неизбежно увидите следы такого API.

4. Проект был реализован без учета параллелизма. Существует огромное количество техник, которые работают очень хорошо в последовательном среде, но не в параллельной. Если ваш проект работал на последовательно аппаратном обеспечении большую часть своей жизни, то он, безусловно, будет иметь хотя бы часть кода, который сложен для распараллеливания.

5. Проект был реализован без учета хороших практик разработки программного обеспечения. Горькая правда в том, что параллельные  среды с разделяемой памятью часто менее простительны к плохим практикам разработки, чем последовательные. Вам лучше улучшить текущий дизайн и убрать беспорядок перед тем как начать параллелизацию.

6. Люди, которые изначально разрабатывали ваш проект - ушли. А те, кто остались, хоть и могут поддерживать его и добавлять небольшую функциональность, не могут сделать глобальные изменения. В этом случае, если вы не можете придумать простой способ распараллелизировать ваш проект, вам лучше оставить его последовательным. При всем этом, есть несколько простых подходов, которые вы можете использовать: 

* запустить нескольких экземпляров программы;
* использовать параллельную реализацую некой часто используемой библиотечной функции;
* использовать другой параллельный проект, такой как база данных.

Конечно, можно сказать что большинство из этих препятствий нетехнические по своей природе, но это не делает их менее реальными. Короче говоря, параллелизация большого участка кода может быть большой и тяжелой работой. И как с любой такой работой, к ней лучше заранее подготовится.
